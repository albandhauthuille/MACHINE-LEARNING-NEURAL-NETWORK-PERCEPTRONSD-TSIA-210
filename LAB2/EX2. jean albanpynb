{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iafPdtuncbq7"
   },
   "source": [
    "<h1><center>Autoencoder on MNIST using Keras<center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4VrCB5La5rD"
   },
   "source": [
    "## Importing Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OlKZ3Hnas7B4",
    "outputId": "c68acc01-8a3d-428b-adb6-c35d61a2a868"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "## Loading and preparing the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLtK5hWxUUDD"
   },
   "source": [
    "Load the MNIST dataset via keras.datasets. Again, turn train and test labels into one-hot encoding, and reshape and normalize data as in the first exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "gG83hGyVmijn",
    "outputId": "196d30d8-63d4-4737-c472-ada2e56f583d"
   },
   "outputs": [],
   "source": [
    "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
    "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
    "from keras.datasets import ...\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lQbkllF8mnaf",
    "outputId": "b1d3ff0a-89e2-4e97-ef2d-daae210855a9"
   },
   "outputs": [],
   "source": [
    "# Do you remember about one-hot encoding ?\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ptTRSDo5nJyZ",
    "outputId": "d8a3db4b-fa52-44a7-899f-9b53c1d6215c"
   },
   "outputs": [],
   "source": [
    "# Reshape to proper images with 1 color channel according to backend scheme\n",
    "img_rows, img_cols = train_images.shape[1], train_images.shape[2]\n",
    "train_images = train_images.reshape(...)\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "\n",
    "# Cast pixels from uint8 to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Now let us normalize the images so that they have zero mean and standard deviation\n",
    "# Hint: are real testing data statistics known at training time ?\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder and PCA\n",
    "\n",
    "First, we will try to connect the representation produced by Principal Component Analysis with what is learnt by a simple, linear, autoencoder. We will use the ```scikit-learn``` implementation of the ```PCA``` to obtain the two first components (hint: use the attribute ```.components_```), and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Let's find the first 2 PCA components\n",
    "num_components = 2\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "\n",
    "# Reshape so they resemble images and we can print them\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "\n",
    "# Show the reshaped principal components\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the variance explained by those components\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on the visualization in relation to the variance explained by only keeping the two principal components.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use Keras to implement the autoencoder. You can take a look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf) for some basic commands to use keras.\n",
    "\n",
    "In this first case, we implement a **simple linear autoencoder**. Build it in order to have the same capacity as the PCA decomposition (2 hidden dimensions !) we made just above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding layer\n",
    "latent_view = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding layer\n",
    "output_layer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model = Model(input_layer, output_layer, name='ae_model')\n",
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What loss shoud we use ? Choose the usual one and import it directly from Keras. You can use a simple ```SGD``` optimizer, and then compile the model; finally, train it to rebuild images from the original examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import ...\n",
    "loss = ...\n",
    "\n",
    "optimizer = SGD(lr=1e-1) \n",
    "ae_model.compile(optimizer=optimizer, loss=loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "# No noise here - we want to train a simple auto-encoder and compare visually with PCA\n",
    "history = ae_model.fit(...,\n",
    "                       ...,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=1,\n",
    "                       shuffle=True,\n",
    "                       validation_data=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the name of your layer (obtained through the command ```model.summary()```) is ```'layer'```, here is the way to obtained the weights. Visualize the weights of the encoder and compare them to the two components obtained through the PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = ae_model.get_layer('layer').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the two dimensions of the encoder, in a similar manner to the principal components\n",
    "# (after reshaping them as images !)\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, visualize the images rebuild by the network !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few images at random: look from n\n",
    "n = np.random.randint(0,len(test_images)-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few images from n  \n",
    "f, ax = plt.subplots(1,5)\n",
    "for i,a in enumerate(range(n,n+5)):\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction from the model \n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "\n",
    "# ... and plot them \n",
    "f, ax = plt.subplots(1,5)\n",
    "for i,a in enumerate(range(n,n+5)):\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same ( = build a new model) with a latent dimension that is largely higher than 2. Compare the visualizations and the images that are rebuilt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising auto-encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can implement a **de-noising autoencoder**. The following function will transform an array of images by adding it random noise. Create a new autoencoder model, this time with **more layers** and **non-linear activations** (like the ReLU) and train it to rebuild the de-noised images. Display some testing images, with noise, and re-built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "    return noisy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data with added noise\n",
    "noisy_train_images = noise(train_images)\n",
    "noisy_test_images = noise(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the images with noise against the originals\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a new model with more layers and Relu activations\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile it but here, use noised data as inputs !\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the images rebuilt by the model !\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assuming that we normalize the images to be in the 0-1 range, what other loss function could we use ?**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP4_1_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
